{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f1rX9JzFKent"
   },
   "outputs": [],
   "source": [
    "#first we need to import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Input\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Hhw32diNpL6_",
    "outputId": "967b4202-a013-476f-d6f7-e71568d13358"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Nikhil\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Nikhil\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "XdVmp5EmKsgy",
    "outputId": "235bbc5d-07ae-450f-ac26-214ad72ca108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we need to import our training data which you can download through kaggle - https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/code\n",
    "\n",
    "df=pd.read_csv(\"IMDB Dataset.csv\")\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "tRJFs_9OPC4N",
    "outputId": "7c54060d-d6b7-4aec-93d9-adb7113116b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  negative\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data's dimentions and other information\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yM3wUrNULUdA",
    "outputId": "49abf47f-8912-4978-9487-2dec9b41a41b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postive  25000\n",
      "negative  25000\n"
     ]
    }
   ],
   "source": [
    "#checking if the data can be trusted , that is it is not much biased towards one side\n",
    "print(\"postive \",np.sum(df[\"sentiment\"]==\"positive\"))\n",
    "print(\"negative \",np.sum(df[\"sentiment\"]==\"negative\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "bpFtVgZJX3d6",
    "outputId": "213b9983-424d-4518-b66b-b126f4dbc908"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically theres a family where a little boy J...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Matteis Love in the Time of Money is a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production The filming tech...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically theres a family where a little boy J...  negative\n",
       "4  Petter Matteis Love in the Time of Money is a ...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now begins the cleaning phase where we remove unneccessary letters and symbols from our data\n",
    "\n",
    "def clear_noise(text):\n",
    "  \n",
    "  # removing html scripts using Beautiful Soup\n",
    "  text1=BeautifulSoup(text)\n",
    "  text1=text1.get_text()\n",
    "\n",
    "  #removing all other character than alphabets and numbers using regular expression\n",
    "  text2=re.sub('[^a-zA-Z0-9\\s]', '', text1)\n",
    "\n",
    "  return text2\n",
    "\n",
    "df[\"review\"]=df[\"review\"].apply(clear_noise)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGwPH9gGk7Ct"
   },
   "outputs": [],
   "source": [
    "# 1. Tokenisation (Breaking down the document into words)\n",
    "\n",
    "def tokenize(text):\n",
    "  return text.split()\n",
    "\n",
    "# 2. Stopword Removal (Removal of words which are not meaningful for the model)\n",
    "\n",
    "sw=set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def stopword_removal(text):\n",
    "  useful_words=[w for w in text if w not in sw]\n",
    "  return useful_words\n",
    "\n",
    "# 3. Lemmatization (Changing all forms of a verb to root form like plays ,played etc. to play)\n",
    "\n",
    "wn=nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "  words=[wn.lemmatize(w) for w in text]\n",
    "  return words\n",
    "\n",
    "# 4. Building a vocabulary (Each sentence will have a feature vector)\n",
    "\n",
    "def myTokenizer(text):\n",
    "  text1=tokenize(text.lower())\n",
    "  text1=stopword_removal(text1)\n",
    "  text1=lemmatize(text1)\n",
    "  return text1\n",
    "\n",
    "cv=CountVectorizer(tokenizer=myTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "k30MI7zmH9bg",
    "outputId": "141d7ea3-2392-45b6-8934-9a459c6b4b74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'by', 'each', \"mustn't\", 'when', 'been', 'other', 'having', 'most', \"don't\", 'over', 'an', 'couldn', 'more', 'for', 'ain', 'above', 'd', 'these', 'those', 'should', 'do', 'or', 'doing', 'who', 'himself', 'where', \"mightn't\", 'own', 'how', 'it', \"didn't\", 'their', 'yourself', 'that', 'all', 'which', 'she', 'shan', \"wasn't\", 'then', 'while', 'him', 'too', 're', 'does', 'as', 'off', 'he', 'with', 'a', \"aren't\", 'under', 'yours', 'm', \"hasn't\", \"weren't\", 'whom', 'herself', 's', 'ma', 'had', 'here', 'shouldn', \"shouldn't\", \"hadn't\", 'we', \"you've\", 'this', 'll', 'there', 'his', 'no', \"you'll\", 'now', 'any', 'than', \"should've\", 'again', 'before', \"haven't\", 'my', 'until', 'through', \"doesn't\", 'aren', 'from', 'didn', 'both', 'once', 'needn', 'can', 'and', 'wasn', 'hasn', 'its', 'haven', 'have', 'against', 'are', 'after', 'hadn', 'ourselves', \"isn't\", 'don', 'is', 'myself', 'to', 'some', 'at', 'just', 'will', 'your', 'was', 'wouldn', 'being', 'not', 'theirs', 'but', 'weren', 'me', \"wouldn't\", 'mightn', 'below', \"couldn't\", 'ours', 't', \"it's\", 'so', 'of', 'out', 'yourselves', 'what', 'in', 'nor', 'themselves', 'them', 'were', 'did', 'same', 'very', 'further', 'into', 'isn', \"you're\", 'the', 'itself', \"she's\", 'y', 'during', 'down', \"needn't\", \"won't\", 'up', 'if', 'about', 'doesn', 'hers', 'her', 'they', 'such', 'only', 'our', 'few', 'you', 'has', 'i', 'o', \"you'd\", 'because', 've', 'be', \"that'll\", 'mustn', 'between', 'why', \"shan't\", 'am', 'won', 'on'}\n"
     ]
    }
   ],
   "source": [
    "print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MV_VoOEBTr8k",
    "outputId": "db00a20e-0d7d-42b5-e3ee-14986b8d1f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000,) <class 'pandas.core.series.Series'>\n",
      "(10000,) <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#Now we need to split our data into training and testing. ideally the ratio should be around 80:20\n",
    "\n",
    "train_x=df.review[:35000]\n",
    "train_y=df.sentiment[:35000]\n",
    "\n",
    "val_x=df.review[35000:40000]\n",
    "val_y=df.sentiment[35000:40000]\n",
    "\n",
    "test_x=df.review[40000:]\n",
    "test_y=df.sentiment[40000:]\n",
    "\n",
    "print(train_x.shape,type(train_x))\n",
    "print(test_x.shape,type(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4UuyurHuD-U"
   },
   "outputs": [],
   "source": [
    "# Applying all the above operations on the training data\n",
    "\n",
    "vectorised_data=cv.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jHqEMUrFwAYx",
    "outputId": "d8ad2778-9a58-4dc0-b2f6-6f980759a834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 166729)\n"
     ]
    }
   ],
   "source": [
    "print(vectorised_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKMbN9YlxKyh"
   },
   "outputs": [],
   "source": [
    "# Converting the test and train data in vectorised form\n",
    "\n",
    "cv_train=cv.transform(train_x)\n",
    "cv_val=cv.transform(val_x)\n",
    "cv_test=cv.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wvB23wTG05xU",
    "outputId": "70d888e4-3f39-4a3b-c652-297f45c178ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 166729)\n",
      "(5000, 166729)\n",
      "(10000, 166729)\n"
     ]
    }
   ],
   "source": [
    "print(cv_train.shape)\n",
    "print(cv_val.shape)\n",
    "print(cv_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kTQopzg4tbI7",
    "outputId": "41ca48d9-7139-4c84-ab8c-afc64ca324ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Labelling the sentiment data\n",
    "\n",
    "lb=LabelBinarizer()\n",
    "sentiment_data=lb.fit_transform(df['sentiment'])\n",
    "print(sentiment_data.shape)\n",
    "\n",
    "train_sentiments=sentiment_data[:35000]\n",
    "val_sentiments=sentiment_data[35000:40000]\n",
    "test_sentiments=sentiment_data[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "RuxYzRVSlp1Z",
    "outputId": "c68dd8fa-60d3-4494-e54e-0221a91aabbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                2667680   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,667,969\n",
      "Trainable params: 2,667,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the MLP (Multi layer perceptron) Model\n",
    "model=Sequential()\n",
    "model.add(Input(shape=(166729,),sparse=True))\n",
    "model.add(Dense(16,activation=\"relu\"))\n",
    "model.add(Dense(16,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iLO1PRG1lsH5",
    "outputId": "8cd29c16-4e1f-48a5-b9db-e94b8e1e81c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.6835 - accuracy: 0.6253 - val_loss: 0.6665 - val_accuracy: 0.7066\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.6454 - accuracy: 0.7488 - val_loss: 0.6275 - val_accuracy: 0.7596\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.6055 - accuracy: 0.7869 - val_loss: 0.5885 - val_accuracy: 0.7854\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.5655 - accuracy: 0.8042 - val_loss: 0.5498 - val_accuracy: 0.7944\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.5264 - accuracy: 0.8160 - val_loss: 0.5124 - val_accuracy: 0.8126\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.4905 - accuracy: 0.8274 - val_loss: 0.4793 - val_accuracy: 0.8212\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.4592 - accuracy: 0.8365 - val_loss: 0.4513 - val_accuracy: 0.8340\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.4327 - accuracy: 0.8439 - val_loss: 0.4278 - val_accuracy: 0.8428\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.4103 - accuracy: 0.8499 - val_loss: 0.4080 - val_accuracy: 0.8492\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.3913 - accuracy: 0.8559 - val_loss: 0.3917 - val_accuracy: 0.8516\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.3747 - accuracy: 0.8609 - val_loss: 0.3783 - val_accuracy: 0.8564\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.3603 - accuracy: 0.8665 - val_loss: 0.3652 - val_accuracy: 0.8628\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.3473 - accuracy: 0.8710 - val_loss: 0.3553 - val_accuracy: 0.8642\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.3357 - accuracy: 0.8756 - val_loss: 0.3454 - val_accuracy: 0.8692\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.3252 - accuracy: 0.8783 - val_loss: 0.3377 - val_accuracy: 0.8712\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.3160 - accuracy: 0.8809 - val_loss: 0.3310 - val_accuracy: 0.8750\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.3071 - accuracy: 0.8849 - val_loss: 0.3244 - val_accuracy: 0.8770\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.2991 - accuracy: 0.8880 - val_loss: 0.3189 - val_accuracy: 0.8780\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.2919 - accuracy: 0.8908 - val_loss: 0.3149 - val_accuracy: 0.8798\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.2850 - accuracy: 0.8942 - val_loss: 0.3104 - val_accuracy: 0.8820\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.2786 - accuracy: 0.8968 - val_loss: 0.3065 - val_accuracy: 0.8844\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.2725 - accuracy: 0.8993 - val_loss: 0.3033 - val_accuracy: 0.8854\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.2670 - accuracy: 0.9007 - val_loss: 0.3019 - val_accuracy: 0.8852\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.2618 - accuracy: 0.9023 - val_loss: 0.2995 - val_accuracy: 0.8866\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.2567 - accuracy: 0.9054 - val_loss: 0.2958 - val_accuracy: 0.8878\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.2519 - accuracy: 0.9063 - val_loss: 0.2939 - val_accuracy: 0.8886\n",
      "Epoch 27/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 0.2473 - accuracy: 0.9081"
     ]
    }
   ],
   "source": [
    "hist=model.fit(cv_train,train_sentiments,epochs=50,batch_size=512,validation_data=(cv_val,val_sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to check how our model performed by analysing the accuracy and loss after each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "hxkPXU3B1VVB",
    "outputId": "864c9d8d-0624-4f78-c542-b228c848ab44"
   },
   "outputs": [],
   "source": [
    "h=hist.history\n",
    "plt.plot(h['val_loss'],label=\"validation loss\")\n",
    "plt.plot(h['loss'],label=\"training_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "QeJ8Qoem4XqL",
    "outputId": "3281e08b-7bc8-421f-82c4-c737d4867583"
   },
   "outputs": [],
   "source": [
    "plt.plot(h['accuracy'],label=\"training_accuracy\")\n",
    "plt.plot(h['val_accuracy'],label=\"val_accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_Dl_98dM5n2t",
    "outputId": "50ef4b6a-212e-434e-efa8-1091691b44b1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(cv_test,test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model performed decent with an accuracy of around 90 %"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
